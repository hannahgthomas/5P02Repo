{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f067dde0-8e9f-44c0-83b3-a0418dc7f81d",
   "metadata": {},
   "source": [
    "**5P02 - Peer Review**\n",
    "\n",
    "**Hannah Thomas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8158b-6c58-4235-bb04-7ced6d9553c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psychopy import visual, event, core, data, gui\n",
    "from psychopy.tools.filetools import fromFile\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Experiment setup\n",
    "expName = 'VisualSearch'\n",
    "dlg = gui.Dlg()\n",
    "dlg.addField('SubjectID:')\n",
    "dlg.addField('Trials Per Cond:')\n",
    "ok_data = dlg.show()\n",
    "if not dlg.OK:\n",
    "    core.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e6c74c-9361-4f00-a61f-4a69877efd60",
   "metadata": {},
   "source": [
    "For this experiment setup, I am using an older version of Psychopy (v2024.1.5) but when I tried to utilize this feature it did not work for me, which might be due to my version of Psychopy (see forum here that explains the functionality): https://www.psychopy.org/api/gui.html\n",
    "\n",
    "In order to have the label show (i.e., SubjectID:), I needed to add dlg.addText above dlg.addField in order to have a label appear. \n",
    "\n",
    "Once I figured out what values I was entering, I had to modify the indexing used below to finally get the experiment to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d510e5-fb45-4e91-bede-a55e024810f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ID = ok_data[0]\n",
    "trials = int(dlg.data[1])\n",
    "fileName = sub_ID + \"_\" + expName\n",
    "dataFile = open(fileName + '.csv', 'w')\n",
    "dataFile.write('SetSize,TP, RT, Correct, Missed\\n') # NOTE: For analyses, you should store the subject ID into the data file as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0371d3d-0b51-425c-83ce-6f5255616f4d",
   "metadata": {},
   "source": [
    "Again, I could not get this to work (another reason I think it might be a version issue). Here, you are indexing sub_ID by position by using ok_data[0] which is the first value inputted into the dlg list. For it to work for me, I needed to index by the name of the value like sub_ID = ok_data['SubjectID:']. I'm not entirely sure why this didn't work for me, but it was a helpful practice in debugging someone elses code. \n",
    "\n",
    "I've run into instances before where I've downloaded experiments/analyses scripts from other researchers, only for it not to work for me. It was a good learning experience to try and get the experiment to run for me, especially now that I have more knowledge about what could potentially be causing the issue (i.e., indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a9d83c-cb63-414f-89b3-1a1a9462029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = visual.Window([1920, 1080], fullscr=False, units='pix') \n",
    "\n",
    "# Stimuli and conditions\n",
    "conditions = [5, 8, 12]\n",
    "stim_size = 30\n",
    "T = visual.ImageStim(win, 'Stimuli/T.png', size=stim_size)\n",
    "L = visual.ImageStim(win, 'Stimuli/L.png', size=stim_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9249e74d-f82e-42ad-82e7-1083ef68e8ae",
   "metadata": {},
   "source": [
    "I did not use pixels for my units, but I had to specify the height and width of my stimuli. It seems by using stim_size = 30, it automatically makes the height = 30 and width = 30. Because you are using pixel units, your stimuli should not change size depending on your screen size. I spent a lot of time trying to fix the aspect ratio of my stimuli, but this appears to be a more roboust method. However, I believe that by using pixels the quality of the image might vary based on the monitor? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3e842-ee85-46bc-9051-0ba256784d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw stimuli at random positions/orientations\n",
    "def pos_and_ori(target, distract, samp_size):\n",
    "    samplelist = list(range(-180, 180, 25))\n",
    "    x = random.sample(samplelist, samp_size)\n",
    "    y = random.sample(samplelist, samp_size)\n",
    "    for n in range(0, samp_size - 1):\n",
    "        orientations = [0, 90, 180, 270]\n",
    "        orin = random.choice(orientations)\n",
    "        distract.ori = orin\n",
    "        distract.pos = (x[n], y[n])\n",
    "        distract.draw()\n",
    "    for n in range(samp_size - 1, samp_size):\n",
    "        target.pos = (x[n], y[n])\n",
    "        target.draw()\n",
    "    return distract, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3169a-e671-407c-a060-5ed7a79a8e9b",
   "metadata": {},
   "source": [
    "I'm impressed that this was placed into a function. \n",
    "\n",
    "The code does work, but I noticed that you draw the distract and target here, when they are not yet specified as visual stimuli. I believe you can just have the function assign the pos and orientation and then return those values. \n",
    "\n",
    "One thing I didn't understand is where the code is retrieving the samp_size value from, I understand that is one of the arguments it takes but by changing it to condition later on it, it makes it appear that these are different things. Using one name consistently would improve readability (i.e., set_size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6918bca4-18fd-4aa1-bd10-ba006551ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if target is present on a given trial\n",
    "def targ_pres(trial_list, total_trials, distract, target, condition_index):\n",
    "    pres_or_not = random.choice(trial_list)\n",
    "    trial_list.remove(pres_or_not)\n",
    "    if pres_or_not <= np.median(total_trials):\n",
    "        targ_there = 0\n",
    "        stimuli = pos_and_ori(distract, distract, condition)\n",
    "    else:\n",
    "        targ_there = 1\n",
    "        stimuli = pos_and_ori(target, distract, condition)\n",
    "    return targ_there, stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6e578-5ffb-469a-bf22-97fd73c76452",
   "metadata": {},
   "source": [
    "This was something I struggled to figure out, how to have the target appear on 50% of trials. The use of np.median(total_trials): makes a lot of sense. It will account for trial blocks with odd numbers. \n",
    "\n",
    "The logic appears to be: if the chosen trial number is less than or equal to the median of all trials then the trial will be a target absent.\n",
    "Else, if the chosen trial number is greater than the median (I guess the opposite of the if) then the trial will be target present. \n",
    "\n",
    "Based on that logic, the target argument from pos_and_ori is replaced with distract. I think this makes sense why you drew the stimulus earlier (but it still hasn't been assigned as a visual stimulus). \n",
    "\n",
    "Additionally, the target_press takes the argument condition_index, which is a another name for the same thing (i.e., set_size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504c906-3e7e-4042-a784-121ab48ad4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get response and RT\n",
    "def KeyGet(trial_duration=2.0, rt=None, resp=None):\n",
    "    startTime = core.getTime()\n",
    "    while core.getTime() - startTime < trial_duration and resp is None:\n",
    "        keys = event.getKeys(keyList=['a', 'd', 'escape'])\n",
    "        if keys:\n",
    "            key = keys[0]\n",
    "            rt = core.getTime() - startTime\n",
    "            if key == 'a':\n",
    "                resp = 'a'\n",
    "                break\n",
    "            elif key == 'd':\n",
    "                resp = 'd'\n",
    "                break\n",
    "            elif key == 'escape':\n",
    "                core.quit()\n",
    "        core.wait(0.01)\n",
    "    if resp is None:\n",
    "        resp = 'no_response'\n",
    "        rt = 999\n",
    "    return resp, rt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4670cd-10a2-494d-bbea-4a15f92befdb",
   "metadata": {},
   "source": [
    "My only critique here is that usually on visual search tasks (based on my knowledge) you would have participants withhold their response on target absent trials. And it's easier on participants to have the key correspond to the letter as well (i.e., use T instead). Response key bindings are important!\n",
    "\n",
    "I will say I do not know enough about the timing functions to critique whether core.getTime() - startTime is the best method for getting reaction time, but I think just rt = respClock.getTime() from lecture 5 would suffice? And making sure that you properly reset the clock after each trial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1445d-6710-4b47-b48a-2b6d5e9f157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate response accuracy and feedback\n",
    "def Response(resp, rt, targ_there):\n",
    "    if resp == 'd' and targ_there == 1:\n",
    "        corr = 1\n",
    "        feedback = 'Correct!'\n",
    "        response_time = round(rt, 2)\n",
    "    elif resp == 'a' and targ_there == 1:\n",
    "        corr = 0\n",
    "        feedback = 'Incorrect!'\n",
    "        response_time = round(rt, 2)\n",
    "    elif resp == 'a' and targ_there == 0:\n",
    "        corr = 1\n",
    "        feedback = 'Correct!'\n",
    "        response_time = round(rt, 2)\n",
    "    elif resp == 'd' and targ_there == 0:\n",
    "        corr = 0\n",
    "        feedback = 'Incorrect'\n",
    "        response_time = round(rt, 2)\n",
    "    elif resp == 'no_response':\n",
    "        corr = 0\n",
    "        feedback = 'No Response'\n",
    "        response_time = 'NA'\n",
    "    return corr, feedback, response_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9fbb85-3f57-4cde-9151-9d0d39696dfc",
   "metadata": {},
   "source": [
    "Good use of function to include this info, I like that you were able to print the RT as well. \n",
    "\n",
    "Smart to use round to display the rt to 2 decimal places, very detail oriented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3c265-1dc8-4081-baff-29152893b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions\n",
    "welcome = ''''\n",
    "Welcome to the Visual Search Task\n",
    "\n",
    "You will see an assortment of shapes in different positions and orientations.\n",
    "Most will be 'L' shapes, but some may contain a 'T' shape.\n",
    "\n",
    "If the T is present, press 'd'.\n",
    "If the T is absent, press 'a'.\n",
    "\n",
    "Respond quickly!\n",
    "Press SPACE to begin 5 practice trials.\n",
    "'''\n",
    "\n",
    "instructions = visual.TextStim(win, color='white', text=welcome, units='norm', height=0.05)\n",
    "instructions.draw()\n",
    "win.flip()\n",
    "keys = event.waitKeys(keyList=['space'])\n",
    "core.wait(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f6379-deb4-4ed9-b3be-aad196c3b601",
   "metadata": {},
   "source": [
    "Good use of the ''' to display multiple lines of text, I actually entered in a page break using \\.n and this seems much easier!\n",
    "\n",
    "One thing here is that the scale units have been switched to norm, I would suggest using consistent units throughout your experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c98732-f0d9-40b9-8ca1-0d398ff7d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice trials\n",
    "practice_trials = range(1, 6)\n",
    "for condition in conditions:\n",
    "    appear = list(practice_trials)\n",
    "    for prac_trials in practice_trials:\n",
    "        targ_there, stimuli = targ_pres(appear, practice_trials, L, T, condition)\n",
    "        resp, rt = KeyGet()\n",
    "        #win.flip() <- adding this here will display the trial, then the feedback on the next trial. \n",
    "        corr, feedback, response_time = Response(resp, rt, targ_there)\n",
    "        cor_feedback = visual.TextStim(win, text=feedback, pos=(0, 30), height=40)\n",
    "        back_rt = visual.TextStim(win, text=response_time, pos=(0, -30), height=40)\n",
    "        cor_feedback.draw()\n",
    "        back_rt.draw()\n",
    "        win.flip()\n",
    "        core.wait(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f5a69-075d-4231-86d8-7cc2c2408e60",
   "metadata": {},
   "source": [
    "In the practice loop and main experiment loop, a critical point here is that the trial itself displayed at the same time as the feedback. This is also a limitation of drawing the stimuli earlier. I have included where you should add the win.flip for this to work properly.\n",
    "\n",
    "Additionally, the number of practice trials was not 5, but instead the 5 * the # of conditions = 3 since you loop through conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c13104-0c5a-471c-9450-a0d3ea434487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main experiment instructions\n",
    "welcome = '''' \n",
    "Practice complete! Now for the real trials.\n",
    "\n",
    "Press SPACE to begin.\n",
    "'''\n",
    "instructions = visual.TextStim(win, color='white', text=welcome, units='pix', height=10)\n",
    "instructions.draw()\n",
    "win.flip()\n",
    "keys = event.waitKeys(keyList=['space'])\n",
    "core.wait(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6c4f0-450c-4722-8083-950fa66ebda7",
   "metadata": {},
   "source": [
    "Instead of creating the instructions stimulus again, you could do instructions.text=welcomeMain to update the text to your new main experiment instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afaf082-617c-46d5-893b-e5ec8860ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial setup\n",
    "total_trials = range(1, trials + 1)\n",
    "rt_list, corr_list, miss_rt_list = [], [], []\n",
    "random.shuffle(conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af54d5-f53e-40e1-818c-778c56a52447",
   "metadata": {},
   "source": [
    "You create the total_trials variable near the bottom of your script, but it is used earlier when creating the function targ_pres. If all it is doing is specifying your number of trials taken from the gui.dlg then I believe you can create it earlier when you create the trials variable. I think it works currently bc you set total_trials as an argument but do not utilize it until before you create the variable. \n",
    "\n",
    "I tried to explore ways to improve this but your trials are not completely random, they are set up in \"blocks\" of set sizes that are randomized, but it is not truly random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39d928a-7d31-443e-b83c-88e0d7164387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main experiment loop\n",
    "for condition in conditions:\n",
    "    appear = list(total_trials)\n",
    "    for trial in total_trials:\n",
    "        targ_there, stimuli = targ_pres(appear, total_trials, L, T, condition)\n",
    "        resp, rt = KeyGet()\n",
    "        # win.flip() <- needs to be added here as well\n",
    "        corr, feedback, response_time = Response(resp, rt, targ_there)\n",
    "        cor_feedback = visual.TextStim(win, text=feedback, pos=(0, 30), height=40)\n",
    "        back_rt = visual.TextStim(win, text=response_time, pos=(0, -30), height=40)\n",
    "        cor_feedback.draw()\n",
    "        back_rt.draw()\n",
    "        win.flip()\n",
    "        core.wait(0.5)\n",
    "\n",
    "        if rt != 999:\n",
    "            rt_list.append(rt)\n",
    "            miss_rt = 0\n",
    "            corr_list.append(corr)\n",
    "        else:\n",
    "            miss_rt_list.append(1)\n",
    "            miss_rt = 1\n",
    "            corr_list.append(0)\n",
    "\n",
    "        dataFile.write('%i, %i, %.3f, %i, %i\\n' % (condition, targ_there, rt, corr, miss_rt))\n",
    "\n",
    "dataFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e37d433-3e28-4ac0-82eb-3978a6827562",
   "metadata": {},
   "source": [
    "Smart to only include your main experimental trials in your data file. I think it would be benefical to store the feedback and keys pressed to determine exactly what kind of error was made. We typically differentiate between hits (correct responses), misses (missing the signal) and false alarms (incorrectly pressing 'd' when you should press 'a'). \n",
    "\n",
    "I couldn't figure out what stimuli was being used for in this loop, it seems unnecessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21fd84-ab81-47a8-92e8-b31b0a25fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final feedback\n",
    "average_rt = round(np.mean(rt_list), 2)\n",
    "average_corr = round(np.mean(corr_list), 2)\n",
    "total_miss = sum(miss_rt_list)\n",
    "\n",
    "avg_rt_text = f'average rt: {average_rt}'\n",
    "avg_corr_text = f'average correct: {average_corr}'\n",
    "miss_text = f'no response on {total_miss} trials'\n",
    "leave_text = 'press SPACE to exit'\n",
    "\n",
    "cor_avg_back = visual.TextStim(win, text=avg_corr_text, pos=(0, 50), height=20)\n",
    "rt_avg_back = visual.TextStim(win, text=avg_rt_text, pos=(0, -10), height=20)\n",
    "miss_tot_back = visual.TextStim(win, text=miss_text, pos=(0, -35), height=20)\n",
    "exit_text = visual.TextStim(win, text=leave_text, pos=(0, -100), height=20)\n",
    "\n",
    "cor_avg_back.draw()\n",
    "rt_avg_back.draw()\n",
    "miss_tot_back.draw()\n",
    "exit_text.draw()\n",
    "\n",
    "win.flip()\n",
    "keys = event.waitKeys(keyList=['space'])\n",
    "win.close()\n",
    "core.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f965c-f613-485a-a6f9-6cce74874a40",
   "metadata": {},
   "source": [
    "I was really impressed with this, since I could not figure it out for my assignment. I see by creating the rt_list, corr_list, and miss_rt_list within the loop and then appending the responses to them you were able to include overall feedback once the experimental loop had finished, awesome stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4ddd2-5e82-4b3b-b5b1-f903845b642c",
   "metadata": {},
   "source": [
    "**Overall Feedback**\n",
    "\n",
    "Overall, this students assignment did an excellent job tackling the challenges of the assignment. I was impressed by the use of functions and also how they did not use trialHandler or experimentHandler demonstrating good knowledge of how to make trials without built-in functions, cool! \n",
    "\n",
    "One reoccuring critique is the name of some variables/arguments were not consistent, and some did not appear to be used. For example, sample_size, condition, and condition_index were used but I think they all referred to the set size. \n",
    "\n",
    "Some inconsistencies in scale units throughout the code.\n",
    "\n",
    "There appeared to be a lot of variables used in earlier functions that were specified later on, which because they were technically unsued they did not create errors but in general I think it's important to always create variables in a logical order to avoid using a function, value, etc. that the program hasn't encountered yet. \n",
    "\n",
    "I learned a lot from this assignment, and I think by reviewing this work and trying to debug it I've gain a better understanding of python. \n",
    "\n",
    "For future courses: I think this assignment would be an excellent practice to include more than once, since I think debugging code is half of the battle and can aid in comprehension. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
